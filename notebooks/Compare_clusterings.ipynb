{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering\n",
    "from kemlglearn.cluster import Leader\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from src.Dataset import read_dataset, get_binary_dataset\n",
    "from src.ConsensusKMeans import ConsensusKMeans\n",
    "import config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Progress: 100%|██████████| 100/100 [00:05<00:00, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_b shape: (150, 725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ls_datasets = ['iris'] # 'pendigits', takes too long\n",
    "d_results = {}\n",
    "d_time = {}\n",
    "# for dataset in ls_datasets:\n",
    "# Load data\n",
    "dataset = 'iris'\n",
    "X, y = read_dataset(dataset)\n",
    "k = len(np.unique(y))\n",
    "    \n",
    "# Get the binary dataset\n",
    "# tic = time.time()\n",
    "X_b, ls_partitions, cluster_sizes = get_binary_dataset(X, k, r=100)\n",
    "# toc = time.time()\n",
    "# d_binary_generation_time[dataset] = toc - tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate ConsensusKMeans for every distance\n",
    "KCC = ConsensusKMeans(n_clusters=k, type='Ucos', normalize=False, cluster_sizes=cluster_sizes)\n",
    "\n",
    "# Hierarchical sklearn clustering\n",
    "\n",
    "HC_ward = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "HC_avg = AgglomerativeClustering(n_clusters=k, linkage='average')\n",
    "HC_single = AgglomerativeClustering(n_clusters=k, linkage='single')\n",
    "HC_comp = AgglomerativeClustering(n_clusters=k, linkage='complete')\n",
    "\n",
    "# Prototype based clustering\n",
    "KM = KMeans(n_clusters=k, n_init=10)\n",
    "\n",
    "# Gaussian Mixture Model\n",
    "GMM_f = GaussianMixture(n_components=k, covariance_type='full', n_init=10)\n",
    "GMM_t = GaussianMixture(n_components=k, covariance_type='tied', n_init=10)\n",
    "GMM_d = GaussianMixture(n_components=k, covariance_type='diag', n_init=10)\n",
    "GMM_s = GaussianMixture(n_components=k, covariance_type='spherical', n_init=10)\n",
    "\n",
    "# Spectral Clustering\n",
    "SC = SpectralClustering(n_clusters=k, n_init=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d_configs = {\n",
    "    HC_ward: {'linkage': 'ward'},\n",
    "    HC_avg: {'linkage': 'average'},\n",
    "    HC_single: {'linkage': 'single'},\n",
    "    HC_comp: {'linkage': 'complete'},\n",
    "    KM: {'n_init': 10},\n",
    "    GMM_f: {'covariance_type': 'full'},\n",
    "    GMM_t: {'covariance_type': 'tied'},\n",
    "    GMM_d: {'covariance_type': 'diag'},\n",
    "    GMM_s: {'covariance_type': 'spherical'},\n",
    "    SC: {'n_init': 10},\n",
    "    KCC: {'n_init': 10,'type': 'Ucos'},\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(clustering, X, y):\n",
    "\n",
    "    tic = time.time()\n",
    "    try:\n",
    "        y_pred = clustering.fit_predict(X)\n",
    "    except:\n",
    "        y_pred = clustering.fit(X).labels_\n",
    "        \n",
    "    toc = time.time()\n",
    "\n",
    "    ARI = adjusted_rand_score(y, y_pred)\n",
    "\n",
    "    print(clustering.__class__.__name__, \"{}\".format(d_configs[clustering]))\n",
    "    print(f\" --ARI: {ARI} ------ Time: {toc - tic}\")\n",
    "\n",
    "    return ARI, toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering {'linkage': 'ward'}\n",
      " --ARI: 0.7311985567707746 ------ Time: 0.0014128684997558594\n",
      "AgglomerativeClustering {'linkage': 'average'}\n",
      " --ARI: 0.7591987071071522 ------ Time: 0.0009963512420654297\n",
      "AgglomerativeClustering {'linkage': 'single'}\n",
      " --ARI: 0.5637510205230709 ------ Time: 0.0010170936584472656\n",
      "AgglomerativeClustering {'linkage': 'complete'}\n",
      " --ARI: 0.6422512518362898 ------ Time: 0.0\n",
      "KMeans {'n_init': 10}\n",
      " --ARI: 0.7302382722834697 ------ Time: 0.04461932182312012\n",
      "GaussianMixture {'covariance_type': 'full'}\n",
      " --ARI: 0.9038742317748124 ------ Time: 0.12523126602172852\n",
      "GaussianMixture {'covariance_type': 'tied'}\n",
      " --ARI: 0.8856970310281228 ------ Time: 0.059294700622558594\n",
      "GaussianMixture {'covariance_type': 'diag'}\n",
      " --ARI: 0.7591987071071522 ------ Time: 0.04039597511291504\n",
      "GaussianMixture {'covariance_type': 'spherical'}\n",
      " --ARI: 0.7302382722834697 ------ Time: 0.03468608856201172\n",
      "SpectralClustering {'n_init': 10}\n",
      " --ARI: 0.7455038681804481 ------ Time: 0.07962274551391602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsensusKMeans {'n_init': 10, 'type': 'Ucos'}\n",
      " --ARI: 0.7455038681804481 ------ Time: 0.600297212600708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ari_hc_w, time_hc = evaluate_clustering(HC_ward, X, y)\n",
    "ari_hc_a, time_hc = evaluate_clustering(HC_avg, X, y)\n",
    "ari_hc_s, time_hc = evaluate_clustering(HC_single, X, y)\n",
    "ari_hc_c, time_hc = evaluate_clustering(HC_comp, X, y)\n",
    "\n",
    "ari_km, time_km = evaluate_clustering(KM, X, y)\n",
    "ari_gmm_f, time_gmm_t = evaluate_clustering(GMM_f, X, y)\n",
    "ari_gmm_t, time_gmm_t = evaluate_clustering(GMM_t, X, y)\n",
    "ari_gmm_d, time_gmm_d = evaluate_clustering(GMM_d, X, y)\n",
    "ari_gmm_s, time_gmm = evaluate_clustering(GMM_s, X, y)\n",
    "\n",
    "ari_sc, time_sc = evaluate_clustering(SC, X, y)\n",
    "\n",
    "ari_kcc, time_kcc = evaluate_clustering(KCC, X_b, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
